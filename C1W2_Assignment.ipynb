{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "jupytext": {
            "main_language": "python"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Week 2: Implementing Callbacks in TensorFlow using the MNIST Dataset\n",
                "\n",
                "In the course you learned how to do classification using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
                "\n",
                "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy. In the lecture you saw how this was done for the loss but here you will be using accuracy instead.\n",
                "\n",
                "Some notes:\n",
                "1. Given the architecture of the net, it should succeed in less than 10 epochs.\n",
                "2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\" and stop training.\n",
                "3. If you add any additional variables, make sure you use the same names as the ones used in the class. This is important for the function signatures (the parameters and names) of the callbacks."
            ],
            "metadata": {
                "id": "_2s0EJ5Fy4u2",
                "azdata_cell_guid": "592dd1d1-e8fb-4518-b640-b11983c2c4c1"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import os\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras"
            ],
            "metadata": {
                "id": "djVOgMHty4u3",
                "azdata_cell_guid": "9ca0e79d-b320-4d2d-9ddd-63f291e305cb"
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "markdown",
            "source": [
                "Begin by loading the data. A couple of things to notice:\n",
                "\n",
                "- The file `mnist.npz` is already included in the current workspace under the `data` directory. By default the `load_data` from Keras accepts a path relative to `~/.keras/datasets` but in this case it is stored somewhere else, as a result of this, you need to specify the full path.\n",
                "\n",
                "- `load_data` returns the train and test sets in the form of the tuples `(x_train, y_train), (x_test, y_test)` but in this exercise you will be needing only the train set so you can ignore the second tuple."
            ],
            "metadata": {
                "azdata_cell_guid": "86c6e233-75b6-49f5-aaf1-6a99706af780"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Load the data\n",
                "\n",
                "# Get current working directory\n",
                "current_dir = os.getcwd()\n",
                "\n",
                "# Append data/mnist.npz to the previous path to get the full path\n",
                "data_path = os.path.join(current_dir, \"data/mnist.npz\")\n",
                "\n",
                "# Discard test set\n",
                "(x_train, y_train), _ = tf.keras.datasets.mnist.load_data(path=data_path)\n",
                "        \n",
                "# Normalize pixel values\n",
                "x_train = x_train / 255.0"
            ],
            "metadata": {
                "azdata_cell_guid": "d7428a42-b84c-4222-9877-0357d7088e7d"
            },
            "outputs": [],
            "execution_count": 7
        },
        {
            "cell_type": "markdown",
            "source": [
                "Now take a look at the shape of the training data:"
            ],
            "metadata": {
                "azdata_cell_guid": "e7a4979e-8701-40cf-904d-f0694b74e05a"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "data_shape = x_train.shape\n",
                "\n",
                "print(f\"There are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"
            ],
            "metadata": {
                "azdata_cell_guid": "abeabf63-41a1-40a2-9d44-21c03ab55f91"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "There are 60000 examples with shape (28, 28)\n"
                }
            ],
            "execution_count": 8
        },
        {
            "cell_type": "markdown",
            "source": [
                "Now it is time to create your own custom callback. For this complete the `myCallback` class and the `on_epoch_end` method in the cell below. If you need some guidance on how to proceed, check out this [link](https://www.tensorflow.org/guide/keras/custom_callback)."
            ],
            "metadata": {
                "azdata_cell_guid": "9ba9aaac-1615-4d3f-a2ae-793beddbb0bb"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# GRADED CLASS: myCallback\n",
                "### START CODE HERE\n",
                "\n",
                "# Remember to inherit from the correct class\n",
                "class myCallback(tf.keras.callbacks.Callback):\n",
                "    #This class is actually created from the Tensorflow's Callback classes\n",
                "    #It makes it possible to use the objects created from this class in Keras neural networks.\n",
                "    \n",
                "        # Define the correct function signature for on_epoch_end\n",
                "        def on_epoch_end(self, epoch, logs={}):\n",
                "            \n",
                "            # Halts the training after reaching 99 percent accuracy\n",
                "            #Args:\n",
                "              #epoch (integer) - index of epoch (required but unused in the function definition below)\n",
                "              #logs (dict) - metric results from the training epoch\n",
                "            \n",
                "            if ((logs.get('accuracy') is not None) and (logs.get('accuracy') > 0.99)): # @KEEP\n",
                "                print(\"\\nReached 99% accuracy so cancelling training!\") \n",
                "                \n",
                "                # Stop training once the above condition is met\n",
                "                self.model.stop_training = True"
            ],
            "metadata": {
                "azdata_cell_guid": "0077cd6a-8a3c-4815-a63e-513463f8f845"
            },
            "outputs": [],
            "execution_count": 15
        },
        {
            "cell_type": "markdown",
            "source": [
                "Now that you have defined your callback it is time to complete the `train_mnist` function below:"
            ],
            "metadata": {
                "azdata_cell_guid": "89aad545-417e-4de2-bb41-390f53c399d1"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# GRADED FUNCTION: train_mnist\n",
                "def train_mnist(x_train, y_train):\n",
                "\n",
                "    ### START CODE HERE\n",
                "    \n",
                "    # Instantiate the callback class\n",
                "    #Create the object 'callbacks' from the class\n",
                "    callbacks = myCallback()\n",
                "    \n",
                "    # Define the model, it should have 3 layers:\n",
                "    # - A Flatten layer that receives inputs with the same shape as the images\n",
                "    # - A Dense layer with 512 units and ReLU activation function\n",
                "    # - A Dense layer with 10 units and softmax activation function\n",
                "    model = tf.keras.models.Sequential([ \n",
                "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
                "        #The input shape for the flatten must be the shape of the images: 28 x 28 pixels\n",
                "        #In keras, all images must have the same sizes, i.e., the same input shapes.\n",
                "        #Flatten converts the 2-Dimensional images into 1-D arrays.\n",
                "        tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
                "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
                "        #10 POSSIBLE CLASSIFICATIONS - Then, this layer has 10 neurons\n",
                "    ]) \n",
                "\n",
                "    # Compile the model\n",
                "    model.compile(optimizer='adam', \n",
                "                  loss='sparse_categorical_crossentropy', \n",
                "                  metrics=['accuracy'])\n",
                "    \n",
                "    #'sparse_categorical_crossentropy' is a loss metric adequate for classification problems, not for regression ones.\n",
                "    #For regressions, we use 'mean_squared_error', for instance.\n",
                "    \n",
                "    # Fit the model for 10 epochs adding the callbacks\n",
                "    # and save the training history\n",
                "    history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
                "    #This command will run only if the object [callbacks] was correctly created from a class\n",
                "    #constructed using the Tensorflow's Callback class.\n",
                "    #Notice that this command calls the callback only at the end of the epoch (training cycle).\n",
                "    #During an epoch, the metrics may vary, going up and down as result of the fact that the neural network\n",
                "    #did not processed all batch data yet. Then, using the callback only at the end of the epoch guarantees that the process\n",
                "    #will not be finished only as consequence of the fact that the backpropagation has not analyzed all data yet.\n",
                "\n",
                "    return history"
            ],
            "metadata": {
                "id": "rEHcB3kqyHZ6",
                "azdata_cell_guid": "4f87c518-37bb-48fb-b83c-8cfba21db4d7"
            },
            "outputs": [],
            "execution_count": 16
        },
        {
            "cell_type": "markdown",
            "source": [
                "Call the `train_mnist` passing in the appropiate parameters to get the training history:"
            ],
            "metadata": {
                "azdata_cell_guid": "8da17d61-061e-4040-98d7-7af592f1b0ce"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "hist = train_mnist(x_train, y_train)"
            ],
            "metadata": {
                "id": "sFgpwbGly4u4",
                "azdata_cell_guid": "b2060174-65f8-4fcd-adae-de1b6cf8c3e1"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Epoch 1/10\n1875/1875 [==============================] - 8s 4ms/step - loss: 0.2018 - accuracy: 0.9402\nEpoch 2/10\n1875/1875 [==============================] - 8s 4ms/step - loss: 0.0802 - accuracy: 0.9749\nEpoch 3/10\n1875/1875 [==============================] - 8s 4ms/step - loss: 0.0527 - accuracy: 0.9835\nEpoch 4/10\n1875/1875 [==============================] - 8s 4ms/step - loss: 0.0364 - accuracy: 0.9877\nEpoch 5/10\n1862/1875 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9913\nReached 99% accuracy so cancelling training!\n1875/1875 [==============================] - 8s 4ms/step - loss: 0.0270 - accuracy: 0.9912\n"
                }
            ],
            "execution_count": 17
        },
        {
            "cell_type": "markdown",
            "source": [
                "If you see the message `Reached 99% accuracy so cancelling training!` printed out after less than 10 epochs it means your callback worked as expected. "
            ],
            "metadata": {
                "azdata_cell_guid": "fbf19fc7-4816-40e8-9471-b879f8bcec47"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Congratulations on finishing this week's assignment!**\n",
                "\n",
                "You have successfully implemented a callback that gives you more control over the training loop for your model. Nice job!\n",
                "\n",
                "**Keep it up!**"
            ],
            "metadata": {
                "azdata_cell_guid": "2dc11605-0e14-41c5-a19b-749c0f2b53a1"
            }
        }
    ]
}